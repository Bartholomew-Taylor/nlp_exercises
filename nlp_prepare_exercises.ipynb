{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ce27dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "import nltk\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7697a5",
   "metadata": {},
   "source": [
    "Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "Lowercase everything\n",
    "Normalize unicode characters\n",
    "Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4badc53",
   "metadata": {},
   "outputs": [],
   "source": [
    " def basic_clean(string):\n",
    "    string = string.lower()\n",
    "    string = unicodedata.normalize('NFKD', \n",
    "                          string).encode('ascii', 'ignore').decode('utf-8')\n",
    "    string = re.sub(r'[^a-z0-9\\s]', '', string)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d101dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i once looked to the hill and saw upon it a great fire life was lain low before it and made to be death in its wake'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string = \"I once looked to the hill and saw upon it a GREAT FIRE. Life was lain low before it and made to be death in its wake.\"\n",
    "\n",
    "output_test = basic_clean(test_string)\n",
    "output_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2681a6",
   "metadata": {},
   "source": [
    "Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1e030c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(string):\n",
    "    tokenize = nltk.tokenize.ToktokTokenizer()\n",
    "    string = tokenize.tokenize(string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b465afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'once',\n",
       " 'looked',\n",
       " 'to',\n",
       " 'the',\n",
       " 'hill',\n",
       " 'and',\n",
       " 'saw',\n",
       " 'upon',\n",
       " 'it',\n",
       " 'a',\n",
       " 'great',\n",
       " 'fire',\n",
       " 'life',\n",
       " 'was',\n",
       " 'lain',\n",
       " 'low',\n",
       " 'before',\n",
       " 'it',\n",
       " 'and',\n",
       " 'made',\n",
       " 'to',\n",
       " 'be',\n",
       " 'death',\n",
       " 'in',\n",
       " 'its',\n",
       " 'wake']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test = tokenizer(output_test)\n",
    "output_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9e6802",
   "metadata": {},
   "source": [
    "Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78999ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(string):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    string = [ps.stem(word) for word in string]\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4660d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'onc',\n",
       " 'look',\n",
       " 'to',\n",
       " 'the',\n",
       " 'hill',\n",
       " 'and',\n",
       " 'saw',\n",
       " 'upon',\n",
       " 'it',\n",
       " 'a',\n",
       " 'great',\n",
       " 'fire',\n",
       " 'life',\n",
       " 'wa',\n",
       " 'lain',\n",
       " 'low',\n",
       " 'befor',\n",
       " 'it',\n",
       " 'and',\n",
       " 'made',\n",
       " 'to',\n",
       " 'be',\n",
       " 'death',\n",
       " 'in',\n",
       " 'it',\n",
       " 'wake']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test = stem(output_test)\n",
    "output_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabec954",
   "metadata": {},
   "source": [
    "Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "240a811a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/fullspectrum/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/fullspectrum/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/fullspectrum/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "748780ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(string):\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    lems = [wnl.lemmatize(word) for word in string]\n",
    "    return lems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cda7b33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'onc',\n",
       " 'look',\n",
       " 'to',\n",
       " 'the',\n",
       " 'hill',\n",
       " 'and',\n",
       " 'saw',\n",
       " 'upon',\n",
       " 'it',\n",
       " 'a',\n",
       " 'great',\n",
       " 'fire',\n",
       " 'life',\n",
       " 'wa',\n",
       " 'lain',\n",
       " 'low',\n",
       " 'befor',\n",
       " 'it',\n",
       " 'and',\n",
       " 'made',\n",
       " 'to',\n",
       " 'be',\n",
       " 'death',\n",
       " 'in',\n",
       " 'it',\n",
       " 'wake']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test = lemmatizer(output_test)\n",
    "output_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02eb141f",
   "metadata": {},
   "source": [
    "Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    "This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8af60a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1326dfc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_english = stopwords.words('english')\n",
    "stopwords_english[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b371404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'onc look hill saw upon great fire life wa lain low befor made death wake'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "no_stop = [word for word in output_test if word not in stopwords_english]\n",
    "\n",
    "' '.join(no_stop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b244f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words = [], exclue_words = []):\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    stopwords_english = set(stopwords_english) - set(exclude_words)\n",
    "    string = [word for word in string if word not in stopwords_english]\n",
    "    string = ' '.join(string)\n",
    "    return string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "231d4af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'onc look hill saw upon great fire life wa lain low befor made death wake'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test = remove_stopwords(output_test)\n",
    "output_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c250523",
   "metadata": {},
   "source": [
    "Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37fef27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_articles(topic_list):\n",
    "    file = 'news_articles.json'\n",
    "    if os.path.exists(file):\n",
    "        with open(file) as f:\n",
    "            return json.load(f)\n",
    "    final_list = []\n",
    "    for topic in topic_list:\n",
    "        final_list.extend(scrap_one_page(topic))\n",
    "    with open(file, 'w') as f:\n",
    "        json.dump(final_list, f)\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15299e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_topics = ['business', 'sports', 'technology', 'entertainment']\n",
    "\n",
    "final_list = get_news_articles(list_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ff8596f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Sachin Tendulkar and his wife meet Bill Gates;...</td>\n",
       "      <td>Former cricketer Sachin Tendulkar and his wife...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>'Best wishes to my classmate,' writes Gates in...</td>\n",
       "      <td>Businessman Anand Mahindra on Tuesday met Micr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Ambanis should get Z+ security cover across In...</td>\n",
       "      <td>The Supreme Court on Tuesday stated that the Z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>Apple supplier Foxlink's fire safety systems f...</td>\n",
       "      <td>Most of the fire safety equipment at Apple sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>People consuming 30 GB and paying almost nothi...</td>\n",
       "      <td>Bharti Airtel is looking to raise mobile phone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>Courteney gets star on H'wood Walk of Fame, An...</td>\n",
       "      <td>Actress Courteney Cox was honoured with a star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>Reactions to trailer are too special: Rani on ...</td>\n",
       "      <td>Actress Rani Mukerji said that the reactions t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>It's been pretty psychotic: Shahid Kapoor on h...</td>\n",
       "      <td>Shahid Kapoor spoke about his journey as an ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>Was nervous dancing with Sridevi &amp; Urmila: Ani...</td>\n",
       "      <td>Marking 26 years since the release of his film...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>Was told I can either be composer, lyricist or...</td>\n",
       "      <td>Singer Prateek Kuhad revealed a Bollywood dire...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         category                                              title  \\\n",
       "0        business  Sachin Tendulkar and his wife meet Bill Gates;...   \n",
       "1        business  'Best wishes to my classmate,' writes Gates in...   \n",
       "2        business  Ambanis should get Z+ security cover across In...   \n",
       "3        business  Apple supplier Foxlink's fire safety systems f...   \n",
       "4        business  People consuming 30 GB and paying almost nothi...   \n",
       "..            ...                                                ...   \n",
       "95  entertainment  Courteney gets star on H'wood Walk of Fame, An...   \n",
       "96  entertainment  Reactions to trailer are too special: Rani on ...   \n",
       "97  entertainment  It's been pretty psychotic: Shahid Kapoor on h...   \n",
       "98  entertainment  Was nervous dancing with Sridevi & Urmila: Ani...   \n",
       "99  entertainment  Was told I can either be composer, lyricist or...   \n",
       "\n",
       "                                              content  \n",
       "0   Former cricketer Sachin Tendulkar and his wife...  \n",
       "1   Businessman Anand Mahindra on Tuesday met Micr...  \n",
       "2   The Supreme Court on Tuesday stated that the Z...  \n",
       "3   Most of the fire safety equipment at Apple sup...  \n",
       "4   Bharti Airtel is looking to raise mobile phone...  \n",
       "..                                                ...  \n",
       "95  Actress Courteney Cox was honoured with a star...  \n",
       "96  Actress Rani Mukerji said that the reactions t...  \n",
       "97  Shahid Kapoor spoke about his journey as an ac...  \n",
       "98  Marking 26 years since the release of his film...  \n",
       "99  Singer Prateek Kuhad revealed a Bollywood dire...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = pd.DataFrame(final_list)\n",
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ca3e195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     former cricketer sachin tendulkar wife anjali ...\n",
       "1     businessman anand mahindra tuesday met microso...\n",
       "2     supreme court tuesday stated z security cover ...\n",
       "3     fire safety equipment apple supplier foxlinks ...\n",
       "4     bharti airtel looking raise mobile phone call ...\n",
       "                            ...                        \n",
       "95    actress courteney cox wa honoured star hollywo...\n",
       "96    actress rani mukerji said reaction trailer upc...\n",
       "97    shahid kapoor spoke journey actor calling pret...\n",
       "98    marking 26 year since release film judaai anil...\n",
       "99    singer prateek kuhad revealed bollywood direct...\n",
       "Name: content, Length: 100, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['content'].apply(basic_clean)\\\n",
    ".apply(tokenizer)\\\n",
    ".apply(lemmatizer)\\\n",
    ".apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfc54d4",
   "metadata": {},
   "source": [
    "a. lem\n",
    "b. stem\n",
    "c. stem if you're on time and money"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
